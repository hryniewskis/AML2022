{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ccd3a9",
   "metadata": {},
   "source": [
    "### Libraries, functions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217192de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.special import expit\n",
    "\n",
    "import measures\n",
    "from model import LogReg\n",
    "from preprocessing import Preprocessor\n",
    "import experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2413c",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df = pd.read_csv('data/bank-additional-full.csv', sep=';')\n",
    "\n",
    "X_bank=bank_df.drop(columns='y')\n",
    "y_bank=(bank_df['y'] == 'yes').astype(int)\n",
    "\n",
    "prep_bank = Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bank_train, X_bank_test, y_bank_train, y_bank_test = prep_bank.train_test_split(X_bank, y_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f69b892",
   "metadata": {},
   "source": [
    "In the task requierements we're asked to remove collinear variables, so we're left with only first 4 options. The GD and SGD results for these 4 are very similar (close to 63%). Thats why I would suggest taking the one where the remaining 2 achieve the best results (which in this case is no scaling and no target balancing). The remaining tests will be perfomed in this particular situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e34cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_coll,balance_classes,scaling=True,True,True\n",
    "X_train=X_bank_train.copy()\n",
    "X_test=X_bank_test.copy()\n",
    "y_train=y_bank_train.copy()\n",
    "y_test=y_bank_test.copy()\n",
    "\n",
    "#One Hot Encoding\n",
    "X_train = prep_bank.one_hot_encoding_fit_transform(X_train)\n",
    "X_test = prep_bank.one_hot_encoding_transform(X_test)\n",
    "\n",
    "if remove_coll:\n",
    "    X_train = prep_bank.remove_multicollinearity_fit_transform(X_train)\n",
    "    X_test = prep_bank.remove_multicollinearity_transform(X_test)\n",
    "if balance_classes:\n",
    "    X_train,y_train=prep_bank.class_balancing(X_train,y_train)\n",
    "if scaling:\n",
    "    s = StandardScaler()\n",
    "    X_train = s.fit_transform(X_train)\n",
    "    X_test = s.transform(X_test)\n",
    "#próbowałem to wrzucić do funkcji preprocess_data, ale coś wywala błąd więc na razie odpuszczam    \n",
    "\n",
    "#X_train=X_train.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "#X_test=X_test.to_numpy()\n",
    "y_test=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7576bdf",
   "metadata": {},
   "source": [
    "#### 1. Convergence analysis: check how the value of log-likelihood function depends on the number of iterations for 4 above algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "n_epochs=1000\n",
    "\n",
    "lr_models = {\n",
    "     'GD': LogReg(optimization='Gradient Descent', learning_rate=lr, epochs=n_epochs, batch_size=32),\n",
    "     'SGD': LogReg(optimization='Stochastic Gradient Descent', learning_rate=lr, epochs=n_epochs),\n",
    "     'IRLS': LogReg(optimization='Iterative Reweighted Least Squares', epochs=n_epochs),\n",
    "     'ADAM': LogReg(optimization='Adaptive Moment Estimation', epochs=n_epochs, learning_rate=0.01, beta_1=0.9,\n",
    "                    beta_2=0.99, epsilon=1e-8)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ade601",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "losses={}\n",
    "for model_name, model in lr_models.items():\n",
    "    model.train(X_train, y_train)\n",
    "    losses[model_name]=model.get_optimizer_training_losses()\n",
    "    plt.plot(range(len(losses[model_name])), losses[model_name], label=model_name)\n",
    "plt.title('All 4 implementations',fontsize='xx-large')\n",
    "plt.xlabel(\"Iteration\",fontsize='xx-large')\n",
    "plt.ylabel(\"Loss\",fontsize='xx-large')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54fbe2d",
   "metadata": {},
   "source": [
    "#### 2. Check how the value of learning rate and other parameters affect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf42a2d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tested_l_rates=np.linspace(start=1e-1,stop=1e-10,num=10)\n",
    "tested_algorithms={'GD': 'Gradient Descent','SGD':'Stochastic Gradient Descent','ADAM':'Adaptive Moment Estimation'}\n",
    "\n",
    "res_test_learning_rates=experiments.test_learning_rates(X_train,y_train,\n",
    "                                                        X_test,y_test,\n",
    "                                                        tested_l_rates,tested_algorithms)\n",
    "res_test_learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5800df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test_learning_rates[res_test_learning_rates['method']=='ADAM'].sort_values(by=['accuracy','F_measure','recall','precision'],ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_betas_1=np.linspace(start=0.75,stop=.95,num=5)\n",
    "tested_betas_2=np.linspace(start=0.90,stop=0.99,num=10)\n",
    "\n",
    "res_test_betas=experiments.test_betas(X_train, y_train,\n",
    "                                      X_test,y_test,\n",
    "                                      tested_betas_1,tested_betas_2)\n",
    "res_test_betas.sort_values(by=['accuracy','F_measure','recall','precision'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dac190d",
   "metadata": {},
   "source": [
    "#### 4. Compare the classification performance of logistic regression (try all 4 methods: IWLS, GD, SGD and ADAM) and 3 popular classification methods: LDA, QDA and KNN. Use the performance measures implemented in Part 2 and datasets prepared in Part 1. The performance measures should be calculated on test set. If the given algorithm does not converge, within 1000 iterations, stop the algorithm and use the solutions from the last iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc39a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "n_epochs=1000\n",
    "models = {\n",
    "    'GD': LogReg(optimization='Gradient Descent', learning_rate=lr, epochs=n_epochs, batch_size=32),\n",
    "    'SGD': LogReg(optimization='Stochastic Gradient Descent', learning_rate=lr, epochs=n_epochs),\n",
    "    'IRLS': LogReg(optimization='Iterative Reweighted Least Squares', epochs=n_epochs),\n",
    "    'ADAM': LogReg(optimization='Adaptive Moment Estimation', epochs=n_epochs, learning_rate=lr, beta_1=0.8,\n",
    "                   beta_2=0.98, epsilon=1e-8),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'LR': LogisticRegression(max_iter=n_epochs),\n",
    "    'kNN': KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c40266",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final=experiments.final_comparisson(X_train, y_train,\n",
    "                                        X_test,y_test,\n",
    "                                        models)\n",
    "res_final.sort_values(by=['accuracy','f_measure','recall','precision'],ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

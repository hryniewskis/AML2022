{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ccd3a9",
   "metadata": {},
   "source": [
    "### Libraries, functions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217192de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.special import expit\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import measures\n",
    "from model import LogReg\n",
    "from preprocessing import Preprocessor\n",
    "import experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2413c",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "etherneum_df=pd.read_csv('data/transaction_dataset.csv')\n",
    "\n",
    "y_eth=etherneum_df['FLAG']\n",
    "to_drop=['Unnamed: 0','Index','Address','FLAG']\n",
    "X_eth=etherneum_df.drop(columns=to_drop)\n",
    "\n",
    "prep_eth = Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eth_train, X_eth_test, y_eth_train, y_eth_test = prep_eth.train_test_split(X_eth, y_eth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb6fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_binary=[' ERC20 avg time between sent tnx', ' ERC20 avg time between rec tnx',\n",
    "                 ' ERC20 avg time between rec 2 tnx', ' ERC20 avg time between contract tnx',\n",
    "                 ' ERC20 min val sent contract', ' ERC20 max val sent contract', ' ERC20 avg val sent contract']\n",
    "for col in columns_to_binary:\n",
    "    #train set\n",
    "    X_eth_train[col]=X_eth_train[col].fillna(1)\n",
    "    #test set\n",
    "    X_eth_test[col]=X_eth_test[col].fillna(1)\n",
    "#Pomimo obecności SimpleImputera w preprocessorze przy użyciu go było za dużo zabawy z dtype i faktem, że imputer \n",
    "#zwraca NumpyArray a nie DataFrame\n",
    "for col in set(X_eth_train.columns)-set(columns_to_binary):\n",
    "    #train set\n",
    "    X_eth_train[col]=X_eth_train[col].fillna(X_eth_train[col].value_counts().index[0])\n",
    "    #test set\n",
    "    X_eth_test[col]=X_eth_test[col].fillna(X_eth_train[col].value_counts().index[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e34cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_coll,balance_classes,scaling=True,True,False\n",
    "X_train=X_eth_train.copy()\n",
    "X_test=X_eth_test.copy()\n",
    "y_train=y_eth_train.copy()\n",
    "y_test=y_eth_test.copy()\n",
    "if remove_coll:\n",
    "    X_train = prep_eth.remove_multicollinearity_fit_transform(X_train)\n",
    "    X_test = prep_eth.remove_multicollinearity_transform(X_test)\n",
    "if balance_classes:\n",
    "    X_train,y_train=prep_eth.class_balancing(X_train,y_train)\n",
    "if scaling:\n",
    "    s = StandardScaler()\n",
    "    X_train = s.fit_transform(X_train)\n",
    "    X_test = s.transform(X_test)\n",
    "#próbowałem to wrzucić do funkcji preprocess_data, ale coś wywala błąd więc na razie odpuszczam    \n",
    "    \n",
    "#One Hot Encoding\n",
    "X_train = prep_eth.one_hot_encoding_fit_transform(X_train)\n",
    "X_test = prep_eth.one_hot_encoding_transform(X_test)\n",
    "\n",
    "X_train=X_train.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "X_test=X_test.to_numpy()\n",
    "y_test=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7576bdf",
   "metadata": {},
   "source": [
    "#### 1. Convergence analysis: check how the value of log-likelihood function depends on the number of iterations for 4 above algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "n_epochs=1000\n",
    "\n",
    "lr_models = {\n",
    "     'GD': LogReg(optimization='Gradient Descent', learning_rate=lr, epochs=n_epochs, batch_size=32),\n",
    "     'SGD': LogReg(optimization='Stochastic Gradient Descent', learning_rate=lr, epochs=n_epochs),\n",
    "     'IRLS': LogReg(optimization='Iterative Reweighted Least Squares', epochs=n_epochs),\n",
    "     'ADAM': LogReg(optimization='Adaptive Moment Estimation', epochs=n_epochs, learning_rate=0.01, beta_1=0.9,\n",
    "                    beta_2=0.99, epsilon=1e-8)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ade601",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "losses={}\n",
    "for model_name, model in lr_models.items():\n",
    "    model.train(X_train, y_train)\n",
    "    losses[model_name]=model.get_optimizer_training_losses()\n",
    "    plt.plot(range(len(losses[model_name])), losses[model_name], label=model_name)\n",
    "plt.title('All 4 implementations',fontsize='xx-large')\n",
    "plt.xlabel(\"Iteration\",fontsize='xx-large')\n",
    "plt.ylabel(\"Loss\",fontsize='xx-large')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54fbe2d",
   "metadata": {},
   "source": [
    "#### 2. Check how the value of learning rate and other parameters affect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf42a2d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tested_l_rates=np.linspace(start=0.2,stop=1e-5,num=11)\n",
    "tested_algorithms={'GD': 'Gradient Descent','SGD':'Stochastic Gradient Descent','ADAM':'Adaptive Moment Estimation'}\n",
    "\n",
    "res_test_learning_rates=experiments.test_learning_rates(X_train=X_train,\n",
    "                                                        y_train=y_train,\n",
    "                                                        X_test=X_test,\n",
    "                                                        y_test=y_test,\n",
    "                                                        l_rates=tested_l_rates,\n",
    "                                                        algorithms=tested_algorithms)\n",
    "\n",
    "res_test_learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe7f43e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res_test_learning_rgfates[res_test_learning_rates['method']=='ADAM'].sort_values(by=['accuracy','F_measure','recall','precision'],ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_betas_1=np.linspace(start=0.75,stop=.97,num=12)\n",
    "tested_betas_2=np.linspace(start=0.90,stop=0.99,num=10)\n",
    "\n",
    "res_test_betas=experiments.test_betas(X_train=X_train, \n",
    "                                      y_train=y_train,\n",
    "                                      X_test=X_test,\n",
    "                                      y_test=y_test,\n",
    "                                      tested_betas1=tested_betas_1,\n",
    "                                      tested_betas2=tested_betas_2)\n",
    "\n",
    "res_test_betas.sort_values(by=['accuracy','F_measure','recall','precision'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dac190d",
   "metadata": {},
   "source": [
    "#### 4. Compare the classification performance of logistic regression (try all 4 methods: IWLS, GD, SGD and ADAM) and 3 popular classification methods: LDA, QDA and KNN. Use the performance measures implemented in Part 2 and datasets prepared in Part 1. The performance measures should be calculated on test set. If the given algorithm does not converge, within 1000 iterations, stop the algorithm and use the solutions from the last iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc39a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "n_epochs=1000\n",
    "models = {\n",
    "    'GD': LogReg(optimization='Gradient Descent', learning_rate=lr, epochs=n_epochs, batch_size=32),\n",
    "    'SGD': LogReg(optimization='Stochastic Gradient Descent', learning_rate=lr, epochs=n_epochs),\n",
    "    'IRLS': LogReg(optimization='Iterative Reweighted Least Squares', epochs=n_epochs),\n",
    "    'ADAM': LogReg(optimization='Adaptive Moment Estimation', epochs=n_epochs, learning_rate=1e-3, beta_1=0.75,\n",
    "                   beta_2=0.99, epsilon=1e-8),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'LR': LogisticRegression(max_iter=n_epochs),\n",
    "    'kNN': KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c40266",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final=experiments.final_comparisson(X_train=X_train,\n",
    "                                        y_train=y_train,\n",
    "                                        X_test=X_test,\n",
    "                                        y_test=y_test,\n",
    "                                        models=models)\n",
    "\n",
    "res_final.sort_values(by=['accuracy','f_measure','recall','precision'],ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

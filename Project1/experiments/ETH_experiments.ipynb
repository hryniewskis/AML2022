{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ccd3a9",
   "metadata": {},
   "source": [
    "### Libraries, functions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa92ff23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "217192de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.special import expit\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import measures\n",
    "from model import LogReg\n",
    "from preprocessing import Preprocessor\n",
    "import experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2413c",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284c13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "etherneum_df=pd.read_csv('../data/transaction_dataset.csv')\n",
    "\n",
    "y_eth=etherneum_df['FLAG']\n",
    "to_drop=['Unnamed: 0','Index','Address','FLAG']\n",
    "X_eth=etherneum_df.drop(columns=to_drop)\n",
    "\n",
    "prep_eth = Preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-albert",
   "metadata": {},
   "source": [
    "Basic data info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "oriented-tampa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9841 entries, 0 to 9840\n",
      "Data columns (total 51 columns):\n",
      " #   Column                                                Non-Null Count  Dtype  \n",
      "---  ------                                                --------------  -----  \n",
      " 0   Unnamed: 0                                            9841 non-null   int64  \n",
      " 1   Index                                                 9841 non-null   int64  \n",
      " 2   Address                                               9841 non-null   object \n",
      " 3   FLAG                                                  9841 non-null   int64  \n",
      " 4   Avg min between sent tnx                              9841 non-null   float64\n",
      " 5   Avg min between received tnx                          9841 non-null   float64\n",
      " 6   Time Diff between first and last (Mins)               9841 non-null   float64\n",
      " 7   Sent tnx                                              9841 non-null   int64  \n",
      " 8   Received Tnx                                          9841 non-null   int64  \n",
      " 9   Number of Created Contracts                           9841 non-null   int64  \n",
      " 10  Unique Received From Addresses                        9841 non-null   int64  \n",
      " 11  Unique Sent To Addresses                              9841 non-null   int64  \n",
      " 12  min value received                                    9841 non-null   float64\n",
      " 13  max value received                                    9841 non-null   float64\n",
      " 14  avg val received                                      9841 non-null   float64\n",
      " 15  min val sent                                          9841 non-null   float64\n",
      " 16  max val sent                                          9841 non-null   float64\n",
      " 17  avg val sent                                          9841 non-null   float64\n",
      " 18  min value sent to contract                            9841 non-null   float64\n",
      " 19  max val sent to contract                              9841 non-null   float64\n",
      " 20  avg value sent to contract                            9841 non-null   float64\n",
      " 21  total transactions (including tnx to create contract  9841 non-null   int64  \n",
      " 22  total Ether sent                                      9841 non-null   float64\n",
      " 23  total ether received                                  9841 non-null   float64\n",
      " 24  total ether sent contracts                            9841 non-null   float64\n",
      " 25  total ether balance                                   9841 non-null   float64\n",
      " 26   Total ERC20 tnxs                                     9012 non-null   float64\n",
      " 27   ERC20 total Ether received                           9012 non-null   float64\n",
      " 28   ERC20 total ether sent                               9012 non-null   float64\n",
      " 29   ERC20 total Ether sent contract                      9012 non-null   float64\n",
      " 30   ERC20 uniq sent addr                                 9012 non-null   float64\n",
      " 31   ERC20 uniq rec addr                                  9012 non-null   float64\n",
      " 32   ERC20 uniq sent addr.1                               9012 non-null   float64\n",
      " 33   ERC20 uniq rec contract addr                         9012 non-null   float64\n",
      " 34   ERC20 avg time between sent tnx                      9012 non-null   float64\n",
      " 35   ERC20 avg time between rec tnx                       9012 non-null   float64\n",
      " 36   ERC20 avg time between rec 2 tnx                     9012 non-null   float64\n",
      " 37   ERC20 avg time between contract tnx                  9012 non-null   float64\n",
      " 38   ERC20 min val rec                                    9012 non-null   float64\n",
      " 39   ERC20 max val rec                                    9012 non-null   float64\n",
      " 40   ERC20 avg val rec                                    9012 non-null   float64\n",
      " 41   ERC20 min val sent                                   9012 non-null   float64\n",
      " 42   ERC20 max val sent                                   9012 non-null   float64\n",
      " 43   ERC20 avg val sent                                   9012 non-null   float64\n",
      " 44   ERC20 min val sent contract                          9012 non-null   float64\n",
      " 45   ERC20 max val sent contract                          9012 non-null   float64\n",
      " 46   ERC20 avg val sent contract                          9012 non-null   float64\n",
      " 47   ERC20 uniq sent token name                           9012 non-null   float64\n",
      " 48   ERC20 uniq rec token name                            9012 non-null   float64\n",
      " 49   ERC20 most sent token type                           9000 non-null   object \n",
      " 50   ERC20_most_rec_token_type                            8990 non-null   object \n",
      "dtypes: float64(39), int64(9), object(3)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "etherneum_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-worthy",
   "metadata": {},
   "source": [
    "The dataset contains 50 columns out of which about 45 can be valid variables during modelling. About half of them contain missing values. We are going to deal with them by filling with the most frequent values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a924220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eth_train, X_eth_test, y_eth_train, y_eth_test = prep_eth.train_test_split(X_eth, y_eth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-gabriel",
   "metadata": {},
   "source": [
    "The target classes are imbalanced - data balancing may be needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "international-stake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22140921409214093"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eth_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5deb6fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_eth_train.columns:\n",
    "    m_f_v = X_eth_train[col].value_counts().index[0]\n",
    "    #train set\n",
    "    X_eth_train[col]=X_eth_train[col].fillna(m_f_v)\n",
    "    #test set\n",
    "    X_eth_test[col]=X_eth_test[col].fillna(m_f_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e34cd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/.local/lib/python3.6/site-packages/statsmodels/stats/outliers_influence.py:193: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "/home/pawel/.local/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1717: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 numerical features left in dataset  2  categorical\n"
     ]
    }
   ],
   "source": [
    "X_train=X_eth_train.copy()\n",
    "X_test=X_eth_test.copy()\n",
    "y_train=y_eth_train.copy()\n",
    "y_test=y_eth_test.copy()\n",
    "\n",
    "#Coll. removal befor OHE -> fear of curse of dimensionality\n",
    "X_train = prep_eth.remove_multicollinearity_fit_transform(X_train)\n",
    "X_test = prep_eth.remove_multicollinearity_transform(X_test)\n",
    "\n",
    "X_train = prep_eth.one_hot_encoding_fit_transform(X_train)\n",
    "X_test = prep_eth.one_hot_encoding_transform(X_test)\n",
    "\n",
    "\n",
    "X_train_rc=X_train.to_numpy()\n",
    "y_train_rc=y_train.to_numpy()\n",
    "X_test_rc=X_test.to_numpy()\n",
    "y_test_rc=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7576bdf",
   "metadata": {},
   "source": [
    "#### 1. Convergence analysis: check how the value of log-likelihood function depends on the number of iterations for 4 above algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b7d9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "n_epochs=1000\n",
    "\n",
    "lr_models = {\n",
    "     'GD': LogReg(optimization='Gradient Descent', learning_rate=lr, epochs=n_epochs, batch_size=32),\n",
    "     'SGD': LogReg(optimization='Stochastic Gradient Descent', learning_rate=lr, epochs=n_epochs),\n",
    "     'IRLS': LogReg(optimization='Iterative Reweighted Least Squares', epochs=n_epochs),\n",
    "     'ADAM': LogReg(optimization='Adaptive Moment Estimation', epochs=n_epochs, learning_rate=0.01, beta_1=0.9,\n",
    "                    beta_2=0.99, epsilon=1e-8)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ade601",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "losses={}\n",
    "for model_name, model in lr_models.items():\n",
    "    model.train(X_train_rc, y_train_rc)\n",
    "    losses[model_name]=model.get_optimizer_training_losses()\n",
    "    plt.plot(range(len(losses[model_name])), losses[model_name], label=model_name)\n",
    "plt.title('ETH: All 4 implementations',fontsize='xx-large')\n",
    "plt.xlabel(\"Iteration\",fontsize='xx-large')\n",
    "plt.ylabel(\"Loss\",fontsize='xx-large')\n",
    "plt.legend()\n",
    "plt.savefig('ETH_conv_01.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-rubber",
   "metadata": {},
   "source": [
    "#### (1b) Impact of target balancing & data scaling\n",
    "\n",
    "Only target balancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rc_balanced, y_train_rc_balanced = prep_eth.class_balancing(X_train_rc,y_train_rc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "n_epochs=1000\n",
    "\n",
    "lr_models_2 = {\n",
    "     'GD': LogReg(optimization='Gradient Descent', learning_rate=lr, epochs=n_epochs, batch_size=32),\n",
    "     'SGD': LogReg(optimization='Stochastic Gradient Descent', learning_rate=lr, epochs=n_epochs),\n",
    "     'IRLS': LogReg(optimization='Iterative Reweighted Least Squares', epochs=n_epochs),\n",
    "     'ADAM': LogReg(optimization='Adaptive Moment Estimation', epochs=n_epochs, learning_rate=0.01, beta_1=0.9,\n",
    "                    beta_2=0.99, epsilon=1e-8)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "losses={}\n",
    "for model_name, model in lr_models_2.items():\n",
    "    model.train(X_train_rc_balanced, y_train_rc_balanced)\n",
    "    losses[model_name]=model.get_optimizer_training_losses()\n",
    "    plt.plot(range(len(losses[model_name])), losses[model_name], label=model_name)\n",
    "plt.title('ETH: All 4 implementations, target balanced',fontsize='xx-large')\n",
    "plt.xlabel(\"Iteration\",fontsize='xx-large')\n",
    "plt.ylabel(\"Loss\",fontsize='xx-large')\n",
    "plt.legend()\n",
    "plt.savefig('ETH_conv_02.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-thing",
   "metadata": {},
   "source": [
    "Target balancing & data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StandardScaler()\n",
    "X_train_scaled = s.fit_transform(X_train_rc_balanced)\n",
    "X_test_scaled = s.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_models_3 = {\n",
    "     'GD': LogReg(optimization='Gradient Descent', learning_rate=lr, epochs=n_epochs, batch_size=32),\n",
    "     'SGD': LogReg(optimization='Stochastic Gradient Descent', learning_rate=lr, epochs=n_epochs),\n",
    "     'IRLS': LogReg(optimization='Iterative Reweighted Least Squares', epochs=n_epochs),\n",
    "     'ADAM': LogReg(optimization='Adaptive Moment Estimation', epochs=n_epochs, learning_rate=0.01, beta_1=0.9,\n",
    "                    beta_2=0.99, epsilon=1e-8)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "losses={}\n",
    "for model_name, model in lr_models_3.items():\n",
    "    model.train(X_train_scaled, y_train_scaled)\n",
    "    losses[model_name]=model.get_optimizer_training_losses()\n",
    "    plt.plot(range(len(losses[model_name])), losses[model_name], label=model_name)\n",
    "plt.title('ETH: All 4 implementations, target balanced, data scaled',fontsize='xx-large')\n",
    "plt.xlabel(\"Iteration\",fontsize='xx-large')\n",
    "plt.ylabel(\"Loss\",fontsize='xx-large')\n",
    "plt.savefig('ETH_conv_03.svg')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-final",
   "metadata": {},
   "source": [
    "Comparison of algorithms afficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = pd.DataFrame(columns=['algorithm', 'transform', 'accuracy'])\n",
    "for model_name in lr_models:\n",
    "    acc_no_scal = measures.accuracy(lr_models[model_name].predict(X_test), y_test)\n",
    "    acc_balanced = measures.accuracy(lr_models_2[model_name].predict(X_test), y_test)\n",
    "    acc_scaled = measures.accuracy(lr_models_3[model_name].predict(X_test_scaled), y_test_scaled)\n",
    "    comp_df = pd.concat((comp_df, pd.DataFrame({'algorithm': [model_name]*3,\n",
    "                                                'transform': [None, 'Balancing', 'Balancing & scaling'],\n",
    "                                                'accuracy': [acc_no_scal, acc_balanced, acc_scaled]})),\n",
    "                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "sns.barplot(x='algorithm', y='accuracy', data=comp_df, hue='transform')\n",
    "plt.legend(loc=1, title='Data transformation')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('ETH: data transformation impact', fontsize='xx-large')\n",
    "plt.xlabel('Alogrithm', fontsize='xx-large')\n",
    "plt.ylabel('Accuracy on test data', fontsize='xx-large')\n",
    "plt.savefig('ETH_transformation_impact.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54fbe2d",
   "metadata": {},
   "source": [
    "#### 2. Check how the value of learning rate and other parameters affect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf42a2d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tested_l_rates=np.linspace(start=0.2,stop=1e-5,num=11)\n",
    "tested_algorithms={'GD': 'Gradient Descent','SGD':'Stochastic Gradient Descent','ADAM':'Adaptive Moment Estimation'}\n",
    "\n",
    "res_test_learning_rates=experiments.test_learning_rates(X_train=X_train,\n",
    "                                                        y_train=y_train,\n",
    "                                                        X_test=X_test,\n",
    "                                                        y_test=y_test,\n",
    "                                                        l_rates=tested_l_rates,\n",
    "                                                        algorithms=tested_algorithms)\n",
    "\n",
    "res_test_learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe7f43e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res_test_learning_rgfates[res_test_learning_rates['method']=='ADAM'].sort_values(by=['accuracy','F_measure','recall','precision'],ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_betas_1=np.linspace(start=0.75,stop=.97,num=12)\n",
    "tested_betas_2=np.linspace(start=0.90,stop=0.99,num=10)\n",
    "\n",
    "res_test_betas=experiments.test_betas(X_train=X_train, \n",
    "                                      y_train=y_train,\n",
    "                                      X_test=X_test,\n",
    "                                      y_test=y_test,\n",
    "                                      tested_betas1=tested_betas_1,\n",
    "                                      tested_betas2=tested_betas_2)\n",
    "\n",
    "res_test_betas.sort_values(by=['accuracy','F_measure','recall','precision'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dac190d",
   "metadata": {},
   "source": [
    "#### 4. Compare the classification performance of logistic regression (try all 4 methods: IWLS, GD, SGD and ADAM) and 3 popular classification methods: LDA, QDA and KNN. Use the performance measures implemented in Part 2 and datasets prepared in Part 1. The performance measures should be calculated on test set. If the given algorithm does not converge, within 1000 iterations, stop the algorithm and use the solutions from the last iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc39a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "n_epochs=1000\n",
    "models = {\n",
    "    'GD': LogReg(optimization='Gradient Descent', learning_rate=lr, epochs=n_epochs, batch_size=32),\n",
    "    'SGD': LogReg(optimization='Stochastic Gradient Descent', learning_rate=lr, epochs=n_epochs),\n",
    "    'IRLS': LogReg(optimization='Iterative Reweighted Least Squares', epochs=n_epochs),\n",
    "    'ADAM': LogReg(optimization='Adaptive Moment Estimation', epochs=n_epochs, learning_rate=1e-3, beta_1=0.75,\n",
    "                   beta_2=0.99, epsilon=1e-8),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'LR': LogisticRegression(max_iter=n_epochs),\n",
    "    'kNN': KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c40266",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final=experiments.final_comparisson(X_train=X_train,\n",
    "                                        y_train=y_train,\n",
    "                                        X_test=X_test,\n",
    "                                        y_test=y_test,\n",
    "                                        models=models)\n",
    "\n",
    "res_final.sort_values(by=['accuracy','f_measure','recall','precision'],ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
